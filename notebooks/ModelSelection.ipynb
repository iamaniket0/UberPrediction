{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the dagshub tracking server\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/himanshu1703/uber-demand-prediction.mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee5346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='himanshu1703', repo_name='uber-demand-prediction', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b768a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and test data\n",
    "\n",
    "train_data_path = \"../data/processed/train.csv\"\n",
    "test_data_path = \"../data/processed/test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_data_path, parse_dates=[\"tpep_pickup_datetime\"]).set_index(\"tpep_pickup_datetime\")\n",
    "\n",
    "test_df = pd.read_csv(test_data_path, parse_dates=[\"tpep_pickup_datetime\"]).set_index(\"tpep_pickup_datetime\")\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd5417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value in training data\n",
    "\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329ddcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values in the test data\n",
    "\n",
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff1d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make X_train and y_train\n",
    "\n",
    "X_train = train_df.drop(columns=[\"total_pickups\"])\n",
    "\n",
    "y_train = train_df[\"total_pickups\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e91aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make X_test and y_test\n",
    "\n",
    "X_test = test_df.drop(columns=[\"total_pickups\"])\n",
    "\n",
    "y_test = test_df[\"total_pickups\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd48b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c741de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b3423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the data\n",
    "\n",
    "encoder = ColumnTransformer([\n",
    "    (\"ohe\", OneHotEncoder(drop=\"first\",sparse_output=False), [\"region\",\"day_of_week\"])\n",
    "], remainder=\"passthrough\", n_jobs=-1,force_int_remainder_cols=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c1ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1980a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the train and test data\n",
    "\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_test_encoded = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4874da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c9a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the experiment\n",
    "\n",
    "mlflow.set_experiment(\"Model Selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e21935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # start the child run\n",
    "    with mlflow.start_run(nested=True) as child:\n",
    "        \n",
    "        # model name search space\n",
    "        list_of_models = [\"LR\", \"RF\", \"GBR\", \"XGBR\"]\n",
    "        model_name = trial.suggest_categorical(\"model_name\", list_of_models)\n",
    "    \n",
    "        if model_name == \"LR\":\n",
    "            model = LinearRegression()\n",
    "    \n",
    "        elif model_name == \"RF\":\n",
    "            n_estimators_rf = trial.suggest_int(\"n_estimators_rf\",10,100,step=10)\n",
    "            max_depth_rf = trial.suggest_int(\"max_depth_rf\",3,10)\n",
    "            model = RandomForestRegressor(n_estimators=n_estimators_rf, \n",
    "                                          max_depth=max_depth_rf, \n",
    "                                          random_state=42, n_jobs=-1)\n",
    "    \n",
    "        elif model_name == \"GBR\":\n",
    "            n_estimators_gb = trial.suggest_int(\"n_estimators_gb\",10,100,step=10)\n",
    "            learning_rate_gb = trial.suggest_float(\"learning_rate_gb\",1e-4,1e-1, log=True)\n",
    "            model = GradientBoostingRegressor(n_estimators=n_estimators_gb, \n",
    "                                              learning_rate=learning_rate_gb,\n",
    "                                             random_state=42)\n",
    "    \n",
    "        elif model_name == \"XGBR\":\n",
    "            n_estimators_xgb = trial.suggest_int(\"n_estimators_xgb\",10,100,step=10)\n",
    "            learning_rate_xgb = trial.suggest_float(\"learning_rate_xgb\",1e-4,1e-1, log=True)\n",
    "            max_depth_xgb = trial.suggest_int(\"max_depth_xgb\",3,10)\n",
    "            model = XGBRegressor(n_estimators=n_estimators_xgb,\n",
    "                                learning_rate=learning_rate_xgb,\n",
    "                                max_depth=max_depth_xgb)\n",
    "    \n",
    "        # log the model name\n",
    "        mlflow.log_param(\"model_name\",model_name)\n",
    "        \n",
    "        # log the model parameters\n",
    "        mlflow.log_params(model.get_params())\n",
    "        \n",
    "        # fit on the data\n",
    "        model.fit(X_train_encoded,y_train)\n",
    "    \n",
    "        # get the predictions\n",
    "        y_pred = model.predict(X_test_encoded)\n",
    "    \n",
    "        # calculate the loss\n",
    "        loss = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "        # log the metric\n",
    "        mlflow.log_metric(\"MAPE\",loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the objective function\n",
    "\n",
    "with mlflow.start_run(run_name=\"best_model\", nested=True) as parent:\n",
    "\n",
    "    # create a study object\n",
    "    study = optuna.create_study(study_name=\"model_selection\", direction=\"minimize\")\n",
    "    # optimize the objective function\n",
    "    study.optimize(func=objective, n_trials=50, n_jobs=-1)\n",
    "    \n",
    "    # log the best parameters\n",
    "    mlflow.log_params(study.best_params)\n",
    "    # log the best error value\n",
    "    mlflow.log_metric(\"Best_MAPE\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acaedd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best value\n",
    "\n",
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b1ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters\n",
    "\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d2589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model value counts\n",
    "\n",
    "study.trials_dataframe()['params_model_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de0701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history, \n",
    "    plot_parallel_coordinate, \n",
    "    plot_param_importances\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8460bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff46446",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(study, params=[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the linear regression model\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train_encoded, y_train)\n",
    "\n",
    "# get predictions\n",
    "y_pred_train = lr.predict(X_train_encoded) \n",
    "y_pred_test = lr.predict(X_test_encoded)\n",
    "\n",
    "# loss\n",
    "\n",
    "mape_train = mean_absolute_percentage_error(y_train, y_pred_train)\n",
    "mape_test = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "\n",
    "print(\"The training error is \", mape_train)\n",
    "print(\"The test error is \", mape_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab157670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_ridge(trial):\n",
    "    # hyperparameter space\n",
    "    alpha = trial.suggest_float(\"alpha\",30,100)\n",
    "    \n",
    "    # make the model object\n",
    "    ridge = Ridge(alpha=alpha, random_state=42)\n",
    "    \n",
    "    # train the model\n",
    "    ridge.fit(X_train_encoded, y_train)\n",
    "    \n",
    "    # get predictions\n",
    "    y_pred = ridge.predict(X_test_encoded)\n",
    "    \n",
    "    # calculate loss\n",
    "    loss = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create study\n",
    "\n",
    "study = optuna.create_study(study_name=\"tune_model\", direction=\"minimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize\n",
    "\n",
    "study.optimize(func=tune_ridge, n_trials=100, n_jobs=-1, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35099793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters\n",
    "\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa21a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best value\n",
    "\n",
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8551074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f763f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0205058c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4452e33d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e682c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11738da0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
